{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whatsapp chat analyzer\n",
    "## Usages:\n",
    "- **count of who said more a specific word or set of word**  \n",
    "    *input:* (Word : String, regex expression or list of String, chat file: file.txt ) \n",
    "    *output:* a table with times each person in the chat said the word   \n",
    "    e.g.  \n",
    "    *input*:('Tips', 'WA_chat_with_Reservoir_Dogs.txt')  \n",
    "    *ouput*: \n",
    "\n",
    "|Mr.pink|Mr.white|Mr.green|\n",
    "|-------|--------|--------|\n",
    "|  123  |  414   |   12   |\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counter\n",
    "- First of all I've scraped the file to retireve the databases, the first one is the one with messages, the second one contains the changes to the group chat (removed members, added members, changed name, ...).  \n",
    "- Then I proceeded to \"clean\" the first database, removing link and 'media omitted' messages.\n",
    "- Finally I've made the counting script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "f = open('YOUR_PATH_HERE', \"r\", encoding='utf-8') \n",
    "\n",
    "lines = f.readlines()\n",
    "dates = []\n",
    "times = []\n",
    "authors = [] \n",
    "contents = []\n",
    "change_dates = []\n",
    "change_times = []\n",
    "change_authors = []\n",
    "change_actions = []\n",
    "change_targets = []\n",
    "i = 0\n",
    "inserted = 0\n",
    "\n",
    "for l in lines: # for each line of the file\n",
    "    i += 1\n",
    "    m = re.match(r'(.*), (.*) - (.*?): (.*)', l) # we're gonna extract the datas using regex, we can 'cause the file is formatted\n",
    "    if m != None: # if we find something(most of the time) we're gonna add all the new data to our lists \n",
    "        inserted += 1 # and increment the number of match (we'll need this later)\n",
    "        dates.append(m.group(1))\n",
    "        times.append(m.group(2))\n",
    "        authors.append(m.group(3))\n",
    "        contents.append(m.group(4))\n",
    "    else: # if we don't find the correct format is because a '\\n' in the text of the message or because is not a message\n",
    "        m = re.match(r'(.*), (.*) - ([A-Z].*) (.*) ([A-Z].*)', l) # we take another look if it's a changes to the group\n",
    "        if m != None: # if it is we re gonna append to the others list\n",
    "            change_dates.append(m.group(1))\n",
    "            change_times.append(m.group(2))\n",
    "            change_authors.append(m.group(3))\n",
    "            change_actions.append(m.group(4))\n",
    "            change_targets.append(m.group(5))\n",
    "        else: # if it's not a change is the last part of the previous message so we 're gonna add it \n",
    "            contents[inserted-1] = contents[inserted-1] + \" \" + l.replace('\\n', ' ')\n",
    "           \n",
    "        \n",
    "\n",
    "datas = list(zip(dates, times, authors, contents))\n",
    "change_datas = list(zip(change_dates, change_times, change_authors, change_actions, change_targets))\n",
    "\n",
    "df = pd.DataFrame(datas, columns=['Dates', 'Time', 'Author', 'Contents']) # create the first dataframe with message\n",
    "# create the second one with stuff like ('Mr. white changed the group's icon', 'Mr.Pink added Mr. yellow', ecc...)\n",
    "# intially is a little crappy, we'll probably come back on it later to adjust it\n",
    "change_df = pd.DataFrame(change_datas, columns=['Dates', 'Time', 'Author', 'Actions', 'Target'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database manipolation\n",
    "- Removed the 'Media omitted' messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df[df['Contents'] == '<Media omitted>'].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hash table\n",
    "I'll generate an hash table of n rows where n is the number of member of the group chat, the index in the list of each person will be determined by an hash function for string, for collision i'll use the line probing method.  \n",
    "Function = $h(str) = (str[len-1]*26^{(len-1)} + str[len-2]*26^{(len-2)} + ... + str[0]*26^0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_funct(word, tab_lenght): # this is the hash funct for retrieving the index for a given string\n",
    "    index = 0\n",
    "    for char, i in zip(word, range(len(word))): # cycling through characters\n",
    "        index += (ord(char.lower()) - 96) * 26 ** (len(word)-1-i) \n",
    "    index = index % tab_lenght\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tab(list_of_string): \n",
    "    tab = [None] * len(list_of_string)\n",
    "    for string in list_of_string: # for each string in the list\n",
    "        index = hash_funct(string, len(list_of_string)) # i get the index from the funct\n",
    "        while tab[index] != None: # linear probing for collision\n",
    "            index += 1\n",
    "            if index == len(list_of_string): # if I get too high with the index i'll set that to 0\n",
    "                index = 0\n",
    "        tab[index] = string # set the value of index-th value of the string as the name\n",
    "    return tab\n",
    "\n",
    "authors = df['Author'].unique()\n",
    "hash_tab = generate_tab(authors) # generating hash_tab\n",
    "for i in range(len(hash_tab)):\n",
    "    print(i, \": \", hash_tab[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting\n",
    "From here the function that will count the occurances of the given word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(data, words, hash_tab):\n",
    "    classifica = [0]*len(hash_tab) # init of the list, all the values are = 0\n",
    "    contents = list(data['Contents'])\n",
    "    authors = list(data['Author'])\n",
    "    for message, i in zip(contents, range(len(contents))): # for each message\n",
    "        message = message.lower()\n",
    "        for word in words: # for each word in the list of word to check for\n",
    "            if word in message: # if the word is into the message \n",
    "                index = hash_funct(authors[i], len(hash_tab)) # generate the index with the hash function\n",
    "                while hash_tab[index] != authors[i]: # if at the index-th position i don't find the right author \n",
    "                    index += 1 # it means that generating the hash_tab there's been a collision so add 1 to index\n",
    "                    if(index == len(hash_tab)):\n",
    "                        index = 0 # reset when going over lenght of array\n",
    "                classifica[index] += 1 # now i got the right index so i'll increment the value at that index by one\n",
    "    return classifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of words to search\n",
    "to_search = ['YOUR', 'WORDS', 'TO', 'SEARCH']\n",
    "\n",
    "classifica = count(df, to_search, hash_tab) # ranking list, organized like this: \n",
    "classifica_dict = {}                        # at index i ther is the score of i-th person in hash_tab\n",
    "for partecipante, score in zip(hash_tab, classifica): # zipping the 2 array into a dictionary, dropping who has score=0\n",
    "    if score != 0:\n",
    "        classifica_dict.update({partecipante : score})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting\n",
    "- Plotting an histogram for rankings \n",
    "- Plotting a pie chart (total is the total occurance of the words and the peace are how much did a person contributed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[10, 7])\n",
    "width = 0.35\n",
    "\n",
    "bars = ax.bar(classifica_dict.keys(), classifica_dict.values(), width=width, label='YOUR_VALUE', color='green')\n",
    "\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.annotate('{}'.format(height), \n",
    "                    xy=(bar.get_x() + bar.get_width()/2, height), \n",
    "                    xytext=(0, 0),\n",
    "                    textcoords=\"offset points\", \n",
    "                    ha='center', va='bottom') \n",
    "    \n",
    "ax.legend()\n",
    "plt.xticks(rotation=90)\n",
    "str = \"\"\n",
    "for item, i in zip(to_search, range(len(to_search))):\n",
    "        str += item + ' '\n",
    "        if i % 3 == 0:\n",
    "            str += '\\n'\n",
    "ax.set_title('YOUR_FANCY_TITLE')\n",
    "fig.tight_layout() \n",
    "fig.savefig('file_name.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pie chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[15, 15])\n",
    "colors = [1]\n",
    "pie = ax.pie(classifica_dict.values(), colors=np.random.rand(len(classifica_dict),3), \n",
    "             autopct='%1.0f%%', \n",
    "             labels=classifica_dict.keys(), shadow= True, rotatelabels = 270, textprops={'size': 'smaller'})\n",
    "\n",
    "ax.axis('equal')\n",
    "ax.margins(0.15)\n",
    "ax.set_title('YOUR_FANCY_TITLE')\n",
    "fig.tight_layout() \n",
    "fig.savefig('file_name.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
